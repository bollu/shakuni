{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haskell Kōan: weighted coin tossing in < 100 LoC\n",
    "\n",
    "We implement a tiny embedded domain-specific language which allows us to _sample from random variables_ and\n",
    "build computations from them. We also build the less-known but equally important ability to\n",
    "use _conditional reasoning_, where we can condition a random variable on another random variable.\n",
    "\n",
    "Implementing this within haskell with a monadic inteface allows us to leverage the full power of Haskell,\n",
    "making our computations compositional, and our implementation of _conditioning_ concise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "{-# LANGUAGE GADTs #-}\n",
    "import Control.Monad (ap, replicateM)\n",
    "import System.Random (getStdGen, getStdRandom, randomR)\n",
    "import qualified Data.Map as M\n",
    "import Control.Monad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a new GADT called `R`, for *random variable*.\n",
    "It supports only three operations:\n",
    "\n",
    "- `Return` lifts a pure value into a random variable which takes on only one value --- that is, a variable \n",
    "- `Uniform` a uniformly distributed random variable over `[0, 1]`.\n",
    "- `Weigh` to scale the probability of getting a value by a custom scaling factor.\n",
    "\n",
    "It supports a `Functor`, `Applicative`, and `Monad` instance which we implement, to easily\n",
    "build up random computations.\n",
    "\n",
    "Then, we write `runRUnweighted` which shows how to run an `R a` computation to get a _random_ `a` value, \n",
    "without taking into account the weights (hence, `unweighted`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniform random values: [0.79149634,0.7387544,0.7090056,0.11956179,0.1219663]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data R a where\n",
    "  Return :: a -> R a -- ^ lift a pure value\n",
    "  Uniform :: (Float -> R a) -> R a -- ^ uniformly distributed random variable over [0, 1]\n",
    "  Weigh :: Float -> R a -> R a   -- ^ scale the probability of the computation by a factor\n",
    "  \n",
    "instance Functor R where\n",
    "  fmap f (Return x) = Return (f x)\n",
    "  fmap f (Uniform rand2m) = Uniform $ \\r -> fmap f (rand2m r)\n",
    "  fmap f (Weigh w m) = Weigh w (fmap f m) \n",
    "  \n",
    "instance Monad R where\n",
    "  return = Return\n",
    "  Return a >>= f = f a\n",
    "  Uniform rand2m >>= f = Uniform $ \\r -> rand2m r >>= f\n",
    "  (Weigh w m) >>= f = Weigh w (m >>= f)\n",
    "  \n",
    "instance Applicative R where\n",
    "  pure = return\n",
    "  (<*>) = ap\n",
    "  \n",
    "-- | Run a random computation, *not taking into account the weights*.\n",
    "-- | This will be used to run the _traced computation_, which\n",
    "-- | does take into account the weights.\n",
    "runUnweighted :: R a -> IO a\n",
    "runUnweighted (Return a) = return a\n",
    "runUnweighted (Weigh w m) = runUnweighted m\n",
    "runUnweighted (Uniform rand2m) = do\n",
    "  r <- getStdRandom $ randomR (0, 1)\n",
    "  runUnweighted (rand2m r) \n",
    "  \n",
    "\n",
    "-- | A value that is uniformly distributed over (0, 1). Convenient constructor\n",
    "uniform01 :: R Float\n",
    "uniform01 = Uniform Return\n",
    "\n",
    "-- \\ Quick run of the uniform sampler to see what it outputs.\n",
    "runUnweighted (replicateM 5 uniform01) >>= \\xs -> putStrLn $ \"uniform random values: \" <> show xs\n",
    "\n",
    "-- | Change the weight of the rest of the computation. As of now, we cannot\n",
    "-- interpret this.\n",
    "weigh :: Float -> R ()\n",
    "weigh w = Weigh w (Return ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a way to get random numbers _uniformly_ from the range (0, 1) we'll use this to build\n",
    "more complicated random variables --- namely, coins with different biases.\n",
    "\n",
    "`coin p` creates a coin that returns `1` with probability `p`, and `0` with probabilty `(1 - p)`.\n",
    "We pick a number `r` uniformly from `(0, 1)`. If this number is less than `p`, we return `1`, otherwise we\n",
    "return `0`. We can convince ourselves that this is right by looking at some exreme cases:\n",
    "\n",
    "- Consider `coin 0`. Now,  `r < 0` is impossible since `r` is in `[0, 1]`. Hence, _never_ return a `1` (that is,\n",
    "we return `1` with probability `0`)\n",
    "- Vice versa, considr `coin 1`. `r < 1` is always satisfied, since `r` is picked from `[0, 1]`. Hence, we will _always_ return a `1`.\n",
    "\n",
    "Similar reasoning for `coin 0.5` will lead to us argue that we will return both `1` and `0` with probability `0.5`, and this argument can be generalized to a `coin p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coin 0: [0,0,0,0,0,0,0,0,0,0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "coin 1: [1,1,1,1,1,1,1,1,1,1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "coin 0.5: [1,1,1,1,1,0,1,1,0,1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "discrete: [100,10,10,1,10,10,100,1,10,10]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- | 'coin p' returns 1 with probability p, 0 with probability (1 - p) \n",
    "coin :: Num a => Float -> R a\n",
    "coin p = do\n",
    "  r <- uniform01\n",
    "  return $ if r < p then 1 else 0\n",
    "  \n",
    "runUnweighted (replicateM 10 (coin 0)) >>= \\xs -> putStrLn $ \"coin 0: \" <> show xs\n",
    "runUnweighted (replicateM 10 (coin 1)) >>= \\xs -> putStrLn $ \"coin 1: \" <> show xs\n",
    "runUnweighted (replicateM 10 (coin 0.5)) >>= \\xs -> putStrLn $ \"coin 0.5: \" <> show xs\n",
    "\n",
    "\n",
    "-- | Chose a discrete value with uniform probability\n",
    "discrete :: [a] -> R a\n",
    "discrete as = do\n",
    "  r <- uniform01\n",
    "  let ix = floor $ r * (fromIntegral $ length as)\n",
    "  return $ as !! ix\n",
    "  \n",
    "runUnweighted (replicateM 10 (discrete [1, 10, 100])) >>= \\xs -> putStrLn $ \"discrete: \" <> show xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, while the above code for `coin` works, we need to think about the correct condition of `r < p`, and it\n",
    "is not immediate. If we had access to `weigh`, here is an alternate way we could implement `coin`. We first\n",
    "implement this `coin'`, which is `coin` implemented using `weigh`, and then build the infrastructure\n",
    "necessary for this to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coin' 0 (will not work, since we do not have weigh): [0,1,1,0,1,1,0,1,0,1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " -- | A biased coin, created from a fair coin.\n",
    "coin' :: (Eq a, Num a) => Float -> R a\n",
    "coin' b = do\n",
    "  -- | pick heads or tails with uniform probability\n",
    "  fair <- discrete [0, 1]\n",
    "  -- | if the fair coin landed 1...\n",
    "  if fair == 1\n",
    "  then weigh $ b -- weigh the outcome by `b`.\n",
    "  else weigh $ (1 - b) -- otherwise weigh the outcome by `1 - b`.\n",
    "  -- | return the value that was tossed, with the new weight.\n",
    "  return fair\n",
    "  \n",
    "runUnweighted (replicateM 10 (coin' 0)) \n",
    "  >>= \\xs -> putStrLn $ \"coin' 0 (will not work, since we do not have weigh): \" <> show xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for this, we need the ability to take into account the calls to `weigh` we have in the code.\n",
    "For this, we use a technique described first in the [Church programming language paper](https://web.stanford.edu/~ngoodman/papers/churchUAI08_rev2.pdf), and also explained in the paper [Denotational validation of higher-order bayesian inference](https://arxiv.org/abs/1711.03219). \n",
    "\n",
    "The idea is to sample from the space of \"program traces\", where a `Trace` keeps track of:\n",
    "- The final output value --- `traceval`\n",
    "- All the randomness used in producing this output value (the results of all `Uniform` invocations) --- `tracerands`\n",
    "- All weighting that has been done on the output value (the product of all `weigh`s found along this computational tract) --- `traceweight`.\n",
    "\n",
    "We store the traces in a `Trace a` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- | Trace of computation \n",
    "data Trace a = \n",
    "  Trace { traceval :: a\n",
    "        , tracerands :: [Float]\n",
    "        , traceweight :: Float\n",
    "        }\n",
    "\n",
    "-- | Lift a value to a trace. Start it with weight 1.0, no randomness, and the given value\n",
    "liftTrace :: a -> Trace a\n",
    "liftTrace a = Trace a [] 1.0\n",
    "\n",
    "-- | Weigh a trace by the given weight \n",
    "weighTrace :: Float -> Trace a -> Trace a\n",
    "weighTrace w tr = tr {traceweight=(traceweight tr)*w}\n",
    "\n",
    "-- | Record the use of randomness along the trace.\n",
    "recordRandomnessTrace :: Float -> Trace a -> Trace a\n",
    "recordRandomnessTrace r tr = tr {tracerands=r:(tracerands tr)}\n",
    "\n",
    "-- | given a regular computation, edit the computation to trace\n",
    "-- | the computation. \n",
    "traceR :: R a -> R (Trace a)\n",
    "traceR (Return x) = Return $ liftTrace x\n",
    "traceR (Uniform rand2m) = \n",
    "  Uniform $ \\r -> recordRandomnessTrace r <$> (traceR $ rand2m r)\n",
    "traceR (Weigh w m) = \n",
    " Weigh w $ weighTrace w <$> (traceR m) \n",
    "\n",
    "\n",
    "-- | Run the random variable, using the randomness provided until the\n",
    "-- | randomness is exhausted\n",
    "runRWithRandomness :: [Float] -> R a -> R a\n",
    "runRWithRandomness _ (Return a) = Return a\n",
    "-- | Feed the Uniform sampling the randomness we have, and continue running\n",
    "-- with the rest of the randomness\n",
    "runRWithRandomness (r:rs) (Uniform rand2m) =\n",
    "  Uniform $ \\r -> runRWithRandomness rs (rand2m r)\n",
    "-- | ran out of randomness\n",
    "runRWithRandomness [] (Uniform rand2m) = Uniform rand2m \n",
    "runRWithRandomness rs (Weigh w m) = \n",
    "  Weigh w (runRWithRandomness rs m)\n",
    "\n",
    "-- | sample from the computation till we find a trace with\n",
    "-- non zero weight\n",
    "nonZeroWeightTrace :: R (Trace a) -> R (Trace a)\n",
    "nonZeroWeightTrace mt = do\n",
    "  t <- mt\n",
    "  if traceweight t == 0\n",
    "  then nonZeroWeightTrace mt\n",
    "  else return $ t\n",
    "  \n",
    "-- | Take samples from the traced random variable using traced monte caro\n",
    "tracedMhStep :: R (Trace a) -> Trace a -> R (Trace a)\n",
    "tracedMhStep mt t = do\n",
    "  -- | Pick a random position in the randomness of the original trace\n",
    "  ix <- discrete [0..(length $ tracerands t) - 1]\n",
    "  -- | Edit the trace at this position by changing the randomness\n",
    "  r <- uniform01                  \n",
    "  let (randl, randr) = splitAt ix (tracerands t)\n",
    "  -- \\ replace the randomness of the trace at this position with this\n",
    "  -- new random value, and now re-run the computation\n",
    "  let newrand = randl ++ [r] ++ drop 1 randr \n",
    "  -- | re-run the old computation, by feeding it the new randomness\n",
    "  t' <- runRWithRandomness newrand mt \n",
    "     \n",
    "  let ratio = traceweight t' * (fromIntegral . length . tracerands $ t') /\n",
    "               traceweight t * (fromIntegral . length . tracerands $ t)\n",
    "  accept <- uniform01\n",
    "  return $ if accept < ratio then t' else t\n",
    "\n",
    "-- | Repeat the monadic computation n times\n",
    "loopM :: Monad m => Int -> (a -> m a) -> a -> m a\n",
    "loopM 0 _ a = return a\n",
    "loopM n f a = f a >>= loopM (n - 1) f\n",
    "\n",
    "\n",
    "-- | Take samples from a random variable by using traced metropolois hastings   \n",
    "tracedMH :: Int -> R a -> R [a]\n",
    "tracedMH n m = do\n",
    "  -- | create the traced randomness source, and sample fromt ti till we get an acceptable\n",
    "  -- | computation\n",
    "  let tm = traceR m\n",
    "  t <- nonZeroWeightTrace tm\n",
    "  -- | Int -> Trace a -> R [Trace a]\n",
    "  let go 0 t = pure []\n",
    "      go n t = do\n",
    "         t' <- loopM 10 (tracedMhStep tm) $ t\n",
    "         ts <- go (n - 1) t'\n",
    "         return $ t:ts\n",
    "  traces <- go n t\n",
    "  return $ map traceval traces\n",
    "  \n",
    "-- | get N samples from a random varaible that uses `weigh`, by sampling using traced metropolis hastings.\n",
    "runsWeighted :: Int -> R a -> IO [a]\n",
    "runsWeighted n m = runUnweighted $ tracedMH n m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also write a tiny utility to plot many values onto the command line with fancy\n",
    "ASCII-art. This is useful when we want to sample a _large number of things_ and look at\n",
    "histograms with `histogram`, or look at the values, with `printvals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- | List of characters that represent sparklines\n",
    "sparkchars :: String\n",
    "sparkchars = \"_▁▂▃▄▅▆▇█\"\n",
    "\n",
    "-- Convert an int to a sparkline character\n",
    "num2spark :: RealFrac a => a -- ^ Max value\n",
    "  -> a -- ^ Current value\n",
    "  -> Char\n",
    "num2spark maxv curv =\n",
    "   sparkchars !!\n",
    "     (floor $ (curv / maxv) * (fromIntegral (length sparkchars - 1)))\n",
    "\n",
    "-- | Print sparklines with title\n",
    "printvals :: RealFrac a => String -> [a] -> IO ()\n",
    "printvals title vs = do \n",
    "  let maxv = maximum vs\n",
    "  putStrLn $ title ++ \" \" ++ map (num2spark maxv) vs\n",
    "  \n",
    "-- | Create a histogram from values.\n",
    "histogram :: RealFrac a\n",
    "          => String -- ^ title\n",
    "          -> Int -- ^ number of buckets\n",
    "          -> [a] -- values\n",
    "          -> IO ()\n",
    "histogram title nbuckets vs = do\n",
    "        let minv = minimum vs\n",
    "            maxv = maximum vs\n",
    "            perbucket = (maxv - minv) / (fromIntegral nbuckets)\n",
    "            bucket v = floor ((v - minv) / perbucket)\n",
    "            bucketed = M.fromListWith (+) [(bucket v, 1) | v <- vs]\n",
    "        printvals title $ M.elems $ bucketed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now draw our previous coins. a vertical bar means that we got a `1`, and not having a vertical bar\n",
    "means that we got a value `0`. We would expect `bias 0` to have no vertical bars (since we should never get a `1`). Similarly, we would expect `bias 1` to have only vertical bars (since we should always get a `1`).\n",
    "\n",
    "\n",
    "Let's use the machinery we have build to bring `coin'` online (recall that `coin'` was defined using `weigh`,\n",
    "and did not work with our previous `runUnweighted`). We will run both the `coin` and `coin'` for different\n",
    "biases to compare, and check that their outputs look roughly the same.\n",
    "\n",
    "Also note that from this point onward, we will _only use_ `runsWeighted`, since our weighted sampler\n",
    "completely subsumes the unweighted sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coin: bias 0 ____________________"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "coin': bias 0 ____________________"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "coin: bias 0.2 █_█_█________█__██__"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "coin': bias 0.2 █_______█____█______"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "coin: 0.5 █__█████_█_█_█__█___"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "coin': 0.5 _█____████_█████__██"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "coin: 0.8 ███_██████████_█████"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "coin': 0.8 _████__█████_███████"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "coin: 1 ████████████████████"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "coin': 1 ████████████████████"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runsWeighted 20 (coin 0) >>=  printvals \"coin: bias 0\"\n",
    "runsWeighted 20 (coin' 0) >>=  printvals \"coin': bias 0\"\n",
    "\n",
    "putStrLn \"---\"\n",
    "runsWeighted 20 (coin 0.2) >>=  printvals \"coin: bias 0.2\"\n",
    "runsWeighted 20 (coin' 0.2) >>=  printvals \"coin': bias 0.2\"\n",
    "\n",
    "putStrLn \"---\"\n",
    "runsWeighted 20 (coin 0.5) >>=  printvals \"coin: 0.5\"\n",
    "runsWeighted 20 (coin' 0.5) >>=  printvals \"coin': 0.5\"\n",
    "\n",
    "putStrLn \"---\"\n",
    "runsWeighted 20 (coin 0.8) >>=  printvals \"coin: 0.8\"\n",
    "runsWeighted 20 (coin' 0.8) >>=  printvals \"coin': 0.8\"\n",
    "\n",
    "putStrLn \"---\"\n",
    "runsWeighted 20 (coin 1) >>=  printvals \"coin: 1\"\n",
    "runsWeighted 20 (coin' 1) >>=  printvals \"coin': 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the `weigh` mechanism to sample from _any shape of distribution we want_. The idea is this: if we want to sample points with a distribution `d :: Float -> Float`, we will sample uniformly a value `r` in the range `(lo, hi)`, and then _weigh this `r`_ by the distribution `d`.  \n",
    "\n",
    "This allows us to sample from shapes such as:\n",
    "- $f(x) = x^2$\n",
    "- $f(x) = |\\sin x|$\n",
    "- $f(x) = e^{-x^2}$ (gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x^2 ______▁__▁▁▁▂▂▃▂▃▃▄▄▅▇▆▇█_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "|sin x| _▂▄▅▆▇█▆▅▅▃▃_▁▃▃▅▇▇▅▇▅▅▄▃_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "e^{-x^2} ___▁▂▄▅█▆▅▄▃▂____"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "|1-x^2| █▅▄▃▂__▁▂▂▂▃▂▂▃▂▂▁__▂▂▅▅▇_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distributionToR :: (Float, Float) -> (Float -> Float) -> R Float\n",
    "distributionToR (lo, hi) d = do\n",
    "  r <- uniform01\n",
    "  let val = lo + r * (hi - lo)\n",
    "  -- | weigh the sample `val` with weight `d val\n",
    "  weigh $ d val\n",
    "  -- | return the value, with the new weight applied.\n",
    "  return $ val\n",
    "\n",
    "\n",
    "runsWeighted 1000 (distributionToR (0, 6) (^2)) >>= histogram \"x^2\" 25\n",
    "runsWeighted 1000 (distributionToR (0, 6) (abs . sin)) >>= histogram \"|sin x|\" 25\n",
    "runsWeighted 1000 (distributionToR (-6, 6) (\\x -> exp (-1.0 * x * x))) >>= histogram \"e^{-x^2}\" 25\n",
    "runsWeighted 1000 (distributionToR (-2, 2) (\\x -> abs (1 - x*x))) >>= histogram \"|1-x^2|\" 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, all of them seem to work. Let's now use similar ideas to estimate the bias of a coin. The idea is as follows:\n",
    "\n",
    "We have a model of a coin, and we know how likely heads or tails is given the model of a coin. Let's call this\n",
    "$P(d|m)$ (probability of the $d$ata given the $m$odel). This is:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(1|\\text{bias}) &= \\text{bias} \\\\\n",
    "P(0|\\text{bias}) &= 1 - \\text{bias}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "What we want to do is the _inverse problem_.\n",
    "Given observations about coin flips from a coin with an _unknown bias_, we wish to _predict its bias_.\n",
    "That is, we want to find $P(\\text{bias}|\\text{data})$.\n",
    "\n",
    "We solve this problem using Bayes' theorem. We know that\n",
    "\n",
    "$$P(bias|data) = \\frac{P(data|bias) P(bias)}{P(data)}$$ \n",
    "\n",
    "The denominator is normalzation factor that is constant for a fixed dataset. Thus, we write:\n",
    "\n",
    "$$P(bias|data) \\propto P(data|bias) P(bias)$$\n",
    "\n",
    "This, if $P(bias)$ is our _prior belief_ about the biases, then $P(data|bias)$ is how much we need to multiply the\n",
    "prior with to get the _posterios belief_.\n",
    "\n",
    "In our case, as mentioned above, the value of $P(data|bias)$ is:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(1|\\text{bias}) &= \\text{bias} \\\\\n",
    "P(0|\\text{bias}) &= 1 - \\text{bias}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estimate with no data ▇▇▆▇█▆▆▇▆▇_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "estimate with [1] _▁▂▃▃▅▅▇▇█_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "estimate with [0] █▆▅▅▄▃▂▁▁__"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "estimate with [0, 1] ▁▄▆▇█▆▇▅▃▁_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "estimate with [1, 0] ▁▄▅▇▇█▇▆▄▁_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "estimate with [1, 0]x2 _▂▄▅▇█▆▅▂▁_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "estimate with [1, 0]x8 ___▂▅█▇▄▂__"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "estimate with [1, 0]x20 __▂▆█▅▂__"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- | Given a list of observations from a coin and the bias, return a value proportional\n",
    "-- to the coin having that bias. Find this by multiplying by bias if we have a 1, (1 - bias)\n",
    "-- if we have a 0, for each heads/tails we see.\n",
    "estimateBias :: [Int] -> R Float\n",
    "estimateBias obs = do\n",
    "  b <- uniform01 -- ^ Uniform prior\n",
    "  forM_ obs $ \\ob -> \n",
    "    if ob == 1 then weigh b else weigh (1 - b)\n",
    "  return $ b\n",
    "  \n",
    "replicateList :: Int -> [a] -> [a]\n",
    "replicateList n as = mconcat $ replicate n as \n",
    "\n",
    "runsWeighted 1000 (estimateBias []) >>= histogram \"estimate with no data\" 10\n",
    "runsWeighted 1000 (estimateBias [1]) >>= histogram \"estimate with [1]\" 10\n",
    "runsWeighted 1000 (estimateBias [0]) >>= histogram \"estimate with [0]\" 10\n",
    "runsWeighted 1000 (estimateBias [0, 1]) >>= histogram \"estimate with [0, 1]\" 10\n",
    "runsWeighted 1000 (estimateBias [1, 0]) >>= histogram \"estimate with [1, 0]\" 10\n",
    "runsWeighted 1000 (estimateBias [1, 0, 1, 0]) >>= histogram \"estimate with [1, 0]x2\" 10\n",
    "runsWeighted 1000 (estimateBias (replicateList 8 [1, 0])) >>= histogram \"estimate with [1, 0]x8\" 10\n",
    "runsWeighted 1000 (estimateBias (replicateList 20 [1, 0])) >>= histogram \"estimate with [1, 0]x20\" 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the way in which we update the bias: We start with the notion that _any bias is equally likely_,\n",
    "since we pick `b <- uniform01`. Then, as we read the observations, we update the _weight of that given bias `b`_\n",
    "based on Bayes' rule --- if the observation is `1`, we scale with `b`, and if not, we scale with `1 - b`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Haskell",
   "language": "haskell",
   "name": "haskell"
  },
  "language_info": {
   "codemirror_mode": "ihaskell",
   "file_extension": ".hs",
   "name": "haskell",
   "pygments_lexer": "Haskell",
   "version": "8.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
